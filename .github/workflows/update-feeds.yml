name: Update Comic Feeds

# This workflow updates ALL comics daily to ensure we never miss new content
# Smart updates were disabled as comics have irregular publishing schedules
# 
# NOTE: Automatic schedule disabled 2025-11-26 - now runs locally at 3:00 AM CST
# Kept as emergency backup - trigger manually if needed (travel, Mac issues, etc.)

on:
  # Disabled: Now runs locally at 3:00 AM CST via local_master_update.sh
  # schedule:
  #   - cron: '30 9 * * *'  # Run at 9:30 AM UTC daily (3:30 AM CST / 4:30 AM EST)
  workflow_dispatch:  # Manual trigger for emergencies

permissions:
  contents: write
  issues: write

jobs:
  update-feeds:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -e .
          pip install selenium beautifulsoup4
      
      - name: Setup Chrome for authenticated scraping
        uses: browser-actions/setup-chrome@v1
        with:
          chrome-version: stable
      
      - name: Scrape GoComics with authenticated access
        env:
          GOCOMICS_EMAIL: ${{ secrets.GOCOMICS_EMAIL }}
          GOCOMICS_PASSWORD: ${{ secrets.GOCOMICS_PASSWORD }}
          CUSTOM_PAGE_1: ${{ secrets.CUSTOM_PAGE_1 }}
          CUSTOM_PAGE_2: ${{ secrets.CUSTOM_PAGE_2 }}
          CUSTOM_PAGE_3: ${{ secrets.CUSTOM_PAGE_3 }}
          CUSTOM_PAGE_4: ${{ secrets.CUSTOM_PAGE_4 }}
          CUSTOM_PAGE_5: ${{ secrets.CUSTOM_PAGE_5 }}
          CUSTOM_PAGE_6: ${{ secrets.CUSTOM_PAGE_6 }}
        run: |
          # Run GoComics authenticated scraper
          python scripts/authenticated_scraper_secure.py --output-dir ./data
      
      # Comics Kingdom scraping now happens locally on Mac (runs at 12:30 AM)
      # This workflow uses the data files pushed by the local script
      - name: Check for Comics Kingdom data
        run: |
          if ls data/comicskingdom_*.json 1> /dev/null 2>&1; then
            LATEST_FILE=$(ls -t data/comicskingdom_*.json | head -1)
            echo "✅ Found Comics Kingdom data: $LATEST_FILE"
          else
            echo "ℹ️  No Comics Kingdom data found - feeds will be GoComics only"
          fi
          
      - name: Generate RSS feeds from scraped data
        run: |
          # Generate GoComics feeds
          python scripts/update_feeds.py
          
          # Generate Comics Kingdom feeds from locally-scraped data (if available)
          if ls data/comicskingdom_*.json 1> /dev/null 2>&1; then
            echo "Generating Comics Kingdom feeds from local data..."
            python scripts/generate_comicskingdom_feeds.py
          else
            echo "ℹ️  No Comics Kingdom data found, skipping Comics Kingdom feeds"
            echo "   (Run local_comicskingdom_update.sh on your Mac to scrape and push data)"
          fi
          
          # Generate TinyView feeds from locally-scraped data (if available)
          if ls data/tinyview_*.json 1> /dev/null 2>&1; then
            echo "Generating TinyView feeds from local data..."
            python scripts/generate_tinyview_feeds_from_data.py
          else
            echo "ℹ️  No TinyView data found, skipping TinyView feeds"
            echo "   (Run local_tinyview_update.sh on your Mac to scrape and push data)"
          fi
          
          # Generate The Far Side feeds (scrapes directly)
          echo "Generating The Far Side feeds..."
          python scripts/update_farside_feeds.py
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      # TinyView feeds now generated from locally-scraped data (like Comics Kingdom)
      # Local scraping happens at 12:35 AM daily via local_tinyview_update.sh
      # This workflow reads the data files and generates feeds
      
      - name: Commit and push updated feeds
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          git add -f public/feeds/*.xml
          
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Update comic feeds"
            
            # Pull and rebase to handle any changes pushed during workflow run
            git pull --rebase origin main
            
            # Push with retry logic in case of race conditions
            for i in {1..3}; do
              if git push; then
                echo "✅ Successfully pushed feed updates"
                break
              else
                echo "⚠️  Push failed, attempt $i/3"
                if [ $i -lt 3 ]; then
                  echo "Pulling latest changes and retrying..."
                  git pull --rebase origin main
                  sleep 2
                else
                  echo "❌ Failed to push after 3 attempts"
                  exit 1
                fi
              fi
            done
          fi
      
      - name: Notify on failure
        if: failure()
        uses: actions/github-script@v6
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'Feed update failed',
              body: `The feed update workflow failed. Check the [workflow run](${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}) for details.`
            })